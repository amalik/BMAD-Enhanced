---
step: 4
workflow: user-discovery
title: Execute Research
---

# Step 4: Execute Research

Your plan is set. Now it's time to go into the field and learn. This step provides guidance for conducting rigorous, respectful research that produces trustworthy data.

## Why This Matters

The quality of your discovery findings depends entirely on the quality of your data collection. Sloppy notes, leading questions, or confirmation bias during execution will undermine everything that follows. Good fieldwork requires discipline, humility, and genuine curiosity.

## Guidance by Method

### Conducting Contextual Inquiry

**Before the session:**
- Review your discussion guide but do not memorize it -- you need flexibility
- Arrive early and observe the environment before engaging
- Test your recording equipment

**During the session:**
- Start with rapport building (5 minutes of casual conversation)
- Ask the participant to walk you through their normal process
- Use the "master-apprentice" model: "Teach me how you do this"
- Follow their lead -- if they go off-script, follow the thread
- Ask "why" and "tell me more" rather than closed questions
- Note the environment: what's on their desk, screen, walls?
- Capture exact quotes when something feels important

**Key phrases to use:**
- "Can you show me how you'd normally do that?"
- "What were you thinking just now when you paused?"
- "Is that what usually happens, or was that unusual?"
- "You mentioned [X] -- can you tell me more about that?"
- "What would happen if you didn't do that step?"

**Key phrases to avoid:**
- "Would you like it if the product did [X]?" (leading)
- "Don't you think [X] would be better?" (leading)
- "Most people we've talked to say [X]..." (anchoring)
- "That's interesting!" (can steer the conversation)

**After the session:**
- Write up expanded notes within 2 hours while memory is fresh
- Highlight surprising moments, contradictions, and strong emotions
- Note your own reactions and biases ("I assumed X but saw Y")

### Running Diary Studies

**Launch phase:**
- Brief each participant individually (not just via email)
- Walk them through one example entry so they understand the format
- Set expectations: "This should take about 5 minutes per entry"
- Confirm their preferred reminder channel (text, email, app notification)

**During the study:**
- Send daily reminders at consistent times
- Respond to entries within 24 hours with brief acknowledgments
- Ask clarifying follow-up questions on entries that seem rich
- Monitor completion rates -- reach out personally to participants who stop logging
- Do NOT judge or evaluate entries ("There are no wrong answers")

**Managing quality:**
- If entries are too brief, ask: "Can you tell me a bit more about what happened right before/after?"
- If entries are too long, gently remind: "Focus on the moment that felt most significant"
- If entries become repetitive, introduce a prompt variation: "Today, focus specifically on moments of frustration"

### Conducting Ethnographic Observation

**Positioning:**
- Find a vantage point where you can see without being in the way
- Avoid hovering directly behind someone's screen
- If observing a shared space, position yourself as a natural part of the environment

**What to record:**
- Timestamp every observation
- Describe actions objectively: "User clicked back button 3 times" not "User was confused"
- Note the sequence of actions, especially unexpected detours
- Record environmental factors: interruptions, conversations with colleagues, phone checks
- Sketch the physical layout if relevant

**Staying objective:**
- Separate observations from interpretations in your notes
- Use two columns: "I saw/heard" and "I think this means"
- Resist the urge to interpret in the moment -- just capture
- After the session, review your interpretation column critically

**The debrief:**
- After observing, sit with the participant for 15-20 minutes
- Ask them to explain key moments you observed
- Share what surprised you and ask if your interpretation matches their experience
- This is where the richest insights often emerge

### Administering Surveys

**Before launch:**
- Pilot with 3-5 people and watch them complete it (time them, note confusion)
- Revise any question where someone hesitates or asks "what do you mean?"
- Check that response options are mutually exclusive and collectively exhaustive
- Test on mobile -- many respondents will use their phone

**During collection:**
- Monitor response rates daily
- Send one reminder after 3 days, a final reminder at 1 day before close
- Watch for suspicious patterns (all same answers, impossibly fast completion)
- If open-ended responses are thin, consider a follow-up prompt

**Quality checks:**
- Remove responses completed in under 30% of median time
- Flag straight-line responses (same answer for every question)
- Check for contradictory answers that suggest inattention

### Conducting Analytics Review

**Approach:**
- Start with the user journey map and overlay behavioral data at each stage
- Look for drop-offs, loops, and unexpected paths
- Compare segments: do different user groups behave differently?
- Check for temporal patterns: time of day, day of week, seasonality

**What to capture:**
- Key metrics with context (not just numbers, but what they mean)
- Anomalies that warrant qualitative investigation
- Hypotheses generated from the data (to test with other methods)
- Confidence level for each finding (strong signal vs. noisy data)

## Universal Field Notes Best Practices

### The AEIOU Framework

Use this structure for every observation session:

- **A - Activities:** What are people doing? What tasks and steps are involved?
- **E - Environments:** What is the physical or digital space like? What objects and tools are present?
- **I - Interactions:** How do people interact with each other, with tools, with the environment?
- **O - Objects:** What artifacts, devices, and items do people use or create?
- **U - Users:** Who are the people involved? What are their roles, relationships, and emotional states?

### Staying Open

The hardest part of discovery research is staying open to being wrong. Watch for these traps:

- **Confirmation bias:** Noticing evidence that supports your hypothesis and ignoring evidence that contradicts it
- **Premature synthesis:** Jumping to conclusions after 2 sessions instead of waiting for patterns
- **Solution fixation:** Hearing problems and immediately designing solutions in your head
- **Expert blindness:** Assuming you understand the user's perspective because you've been in the domain a long time

**Antidote:** After each session, write down one thing that surprised you. If nothing surprised you, you probably were not listening carefully enough.

---

## Your Turn

As you execute your research, come back and share:
1. Key observations and quotes from your sessions
2. Anything that surprised you or contradicted your assumptions
3. Emerging patterns you're noticing across sessions
4. Any adjustments you need to make to your plan

I'll help you make sense of what you're finding and suggest adjustments to remaining sessions based on what emerges.

## Next Step

When your research execution is complete (or you have enough data to synthesize), I'll load:

{project-root}/_bmad/bme/_vortex/workflows/user-discovery/steps/step-05-organize-data.md
